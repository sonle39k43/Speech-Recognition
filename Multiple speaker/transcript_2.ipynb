{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae353a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quang\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import speech\n",
    "import io\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:\\\\Users\\\\quang\\\\Data Analysis\\\\STECH\\\\Speech-To-Text\\\\Speech-Recognition\\\\Multiple_speaker_detection\\\\Speech2Text.json'\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ade6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'speech-to-text_stech'\n",
    "Name = 'Audio_wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1422b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# tổng hợp bucket hiện có\n",
    "def list_buckets():\n",
    "    \"\"\"Lists all buckets.\"\"\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    buckets = storage_client.list_buckets()\n",
    "\n",
    "    for bucket in buckets:\n",
    "        print(bucket.name)\n",
    "\n",
    "# # tạo 1 bucket có tên\n",
    "# def create_bucket_class_location(bucket_name):\n",
    "#     \"\"\"\n",
    "#     Create a new bucket in the US region with the coldline storage\n",
    "#     class\n",
    "#     \"\"\"\n",
    "#     # bucket_name = \"your-new-bucket-name\"\n",
    "\n",
    "#     storage_client = storage.Client()\n",
    "\n",
    "#     bucket = storage_client.bucket(bucket_name)\n",
    "#     bucket.storage_class = \"COLDLINE\"\n",
    "#     new_bucket = storage_client.create_bucket(bucket, location=\"us\")\n",
    "\n",
    "#     print(\n",
    "#         \"Created bucket {} in {} with storage class {}\".format(\n",
    "#             new_bucket.name, new_bucket.location, new_bucket.storage_class\n",
    "#         )\n",
    "#     )\n",
    "#     return new_bucket\n",
    "\n",
    "# Upload large file tới Cloud, nếu tên bị trùng sẽ ghi đè\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975c96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_rate_channel(audio_file_name):\n",
    "    print(audio_file_name)\n",
    "    with wave.open(audio_file_name, \"rb\") as wave_file:\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        channels = wave_file.getnchannels()\n",
    "        return frame_rate,channels\n",
    "    \n",
    "def Config_GGC(sample_rate_hertz = 44100,\n",
    "                audio_channel_count = 1,\n",
    "                model = None,\n",
    "                enable_automatic_punctuation=True):\n",
    "    if model != None:\n",
    "        config_wav_enhanced = speech.RecognitionConfig(\n",
    "            sample_rate_hertz = sample_rate_hertz,\n",
    "            enable_automatic_punctuation=enable_automatic_punctuation,\n",
    "            language_code = 'vi-VN',\n",
    "            audio_channel_count=audio_channel_count,\n",
    "            model = model,\n",
    "        )\n",
    "    else :\n",
    "        config_wav_enhanced = speech.RecognitionConfig(\n",
    "            sample_rate_hertz = sample_rate_hertz,\n",
    "            enable_automatic_punctuation=True,\n",
    "            language_code = 'vi-VN',\n",
    "            audio_channel_count=audio_channel_count\n",
    "        )\n",
    "    return config_wav_enhanced\n",
    "\n",
    "def Transcribe_Short_Audio(Audio_wav,config_wav_enhanced):\n",
    "    client = speech.SpeechClient()\n",
    "    with io.open(Audio_wav, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    # print(type(audio))\n",
    "    \n",
    "    response = client.recognize(config=config_wav_enhanced, audio=audio)\n",
    "    text = []\n",
    "    for i, result in enumerate(response.results):\n",
    "        alternative = result.alternatives[0]\n",
    "        alter=ConvertDate(alternative.transcript+ '\\n')\n",
    "#         print(\"-\" * 20)\n",
    "#         print(\"First alternative of result {}\".format(i))\n",
    "#         print(\"Transcript: {}\".format(alternative.transcript))\n",
    "        text.append(alter)\n",
    "    return text\n",
    "\n",
    "def Transcribe_Long_Audio(Audio_wav,config_wav_enhanced,\n",
    "                        bucket_name = 'speech_to_text_stech',\n",
    "                        Name = 'Audio_wav'):\n",
    "    client = speech.SpeechClient()\n",
    "    Audio_name = Audio_wav.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    upload_blob(bucket_name,Audio_wav,Name)\n",
    "    \n",
    "    media_uri = \"gs://{}/{}\".format(bucket_name,Name)\n",
    "    long_audi_wav = speech.RecognitionAudio(uri=media_uri)\n",
    "    \n",
    "    \n",
    "    operations = client.long_running_recognize(\n",
    "        config = config_wav_enhanced,\n",
    "        audio = long_audi_wav\n",
    "    )\n",
    "    \n",
    "    response = operations.result(timeout=360)\n",
    "\n",
    "    text = []\n",
    "    \n",
    "    for i, result in enumerate(response.results):\n",
    "            alternative = result.alternatives[0]\n",
    "            alter=ConvertDate(alternative.transcript+ '\\n')\n",
    "#             print(\"-\" * 20)\n",
    "#             print(\"First alternative of result {}\".format(i))\n",
    "#             print(\"Transcript: {}\".format(alternative.transcript))\n",
    "            text.append(alter)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8897b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transcribe_Audios(Folder,config):\n",
    "    audios = os.listdir(Folder)\n",
    "    text = []\n",
    "    i = 0\n",
    "    while i <= len(audios)-1:\n",
    "        audio = os.path.join(Folder,\"{}.wav\".format(i))\n",
    "        length = len(AudioSegment.from_wav(audio))\n",
    "        print('Processing : ', audio)\n",
    "        if length < (60 * 1000):\n",
    "            text.append(Transcribe_Short_Audio(audio,config))\n",
    "        else:\n",
    "            text.append(Transcribe_Long_Audio(audio,config))\n",
    "        i += 1\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f353b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_digit(word):\n",
    "    try:\n",
    "        int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def ConvertDate(text):\n",
    "    month=' tháng '\n",
    "    year=' năm '\n",
    "    for index in range(0,len(text)):\n",
    "        try:\n",
    "            if (text.index(month,index)==index):\n",
    "                dateNum = text[index -1]\n",
    "                monthNum = text[index + len(month)]\n",
    "                if is_digit(dateNum) and is_digit(monthNum):\n",
    "                    text=text[:index] + text[index+len(month)-1:]\n",
    "                    temp = list(text)\n",
    "                    temp[index]='/'\n",
    "                    text = \"\".join(temp)\n",
    "        except Exception as e:\n",
    "            if str(e) in 'substring not found':\n",
    "                pass\n",
    "            else:\n",
    "                raise e\n",
    "        try:\n",
    "            if (text.index(year,index)==index):\n",
    "                monthNum = text[index -1]\n",
    "                yearNum = text[index + len(year)]\n",
    "                if is_digit(monthNum) and is_digit(yearNum):\n",
    "                    text=text[:index] + text[index+len(year)-1:]\n",
    "                    temp = list(text)\n",
    "                    temp[index]='/'\n",
    "                    text = \"\".join(temp)\n",
    "        except Exception as e:\n",
    "            if str(e) in 'substring not found':\n",
    "                pass\n",
    "            else:\n",
    "                raise e\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2c63948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\0.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\0.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\0.wav uploaded to Audio_wav.\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\1.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\2.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\3.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\4.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\5.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\6.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\7.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\8.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\9.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\10.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\11.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\12.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\13.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\14.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\15.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\15.wav uploaded to Audio_wav.\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\16.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\17.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\18.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\18.wav uploaded to Audio_wav.\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\19.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\19.wav uploaded to Audio_wav.\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\20.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\21.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\22.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\23.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\23.wav uploaded to Audio_wav.\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\24.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\25.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\26.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\26.wav uploaded to Audio_wav.\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\27.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\28.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\29.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\29.wav uploaded to Audio_wav.\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\30.wav\n",
      "Processing :  C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\31.wav\n",
      "File C:\\Users\\quang\\Data Analysis\\STECH\\Speech-To-Text\\Speech-Recognition\\Multiple_speaker_detection\\Result2\\31.wav uploaded to Audio_wav.\n"
     ]
    }
   ],
   "source": [
    "Folder = 'C:\\\\Users\\\\quang\\\\Data Analysis\\\\STECH\\\\Speech-To-Text\\\\Speech-Recognition\\\\Multiple_speaker_detection\\\\Result2'\n",
    "Result_txt = 'C:\\\\Users\\\\quang\\\\Data Analysis\\\\STECH\\\\Speech-To-Text\\\\Speech-Recognition\\\\Multiple_speaker_detection\\\\TrackRecord.txt'\n",
    "\n",
    "rate, channel = frame_rate_channel(Folder + '\\\\0.wav')\n",
    "config = Config_GGC(sample_rate_hertz = rate,\n",
    "                audio_channel_count = channel)\n",
    "text = Transcribe_Audios(Folder,config)\n",
    "\n",
    "with open(Result_txt, 'w+', encoding='utf-8') as f:\n",
    "    for t in text:\n",
    "        f.writelines(t)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6bd42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
